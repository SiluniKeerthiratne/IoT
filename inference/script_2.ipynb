{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58061b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silunikeerthiratne/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[9.02402960e-03, 2.01367587e-02, 2.11668015e-02, ...,\n",
      "         9.29805875e-01, 9.49218333e-01, 9.63228762e-01],\n",
      "        [1.88839715e-02, 2.30635032e-02, 2.06848364e-02, ...,\n",
      "         9.60851610e-01, 9.56777573e-01, 9.60256696e-01],\n",
      "        [2.31977738e-02, 4.61424664e-02, 4.78895232e-02, ...,\n",
      "         1.37574494e-01, 1.00626707e-01, 7.45378733e-02],\n",
      "        ...,\n",
      "        [7.34375863e-06, 1.41843557e-05, 1.29567898e-05, ...,\n",
      "         1.75613925e-04, 1.93664309e-04, 1.50466250e-04],\n",
      "        [5.79053903e-06, 9.91659817e-06, 6.66892629e-06, ...,\n",
      "         1.02133876e-04, 2.16766522e-04, 1.90570077e-04],\n",
      "        [8.78977698e-06, 1.55106409e-05, 1.33332296e-05, ...,\n",
      "         4.16680487e-05, 8.00659400e-05, 5.57757812e-05]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2  # Import OpenCV\n",
    "\n",
    "def load_tflite_model(tflite_file):\n",
    "    \"\"\"Loads a TensorFlow Lite model.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "def preprocess_image(image_path, input_size):\n",
    "    \"\"\"\n",
    "    Reads, resizes, and preprocesses an image for TFLite inference.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    img = cv2.resize(img, input_size)\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "def run_inference(interpreter, image):\n",
    "    \"\"\"Runs inference on a TFLite model.\"\"\"\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    output_data = [interpreter.get_tensor(detail['index']) for detail in output_details]\n",
    "    return output_data\n",
    "\n",
    "# Example usage:\n",
    "# tflite_file = \"yolov9.tflite\"\n",
    "image_path = \"/Users/silunikeerthiratne/Documents/IoT/inference/images/8.png\"  # Replace with your image path\n",
    "\n",
    "interpreter = load_tflite_model(\"/Users/silunikeerthiratne/Documents/IoT/inference/best-136_float16.tflite\")\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "input_size = input_details[0]['shape'][1:3]  # Get input height and width\n",
    "\n",
    "preprocessed_image = preprocess_image(image_path, input_size)\n",
    "output_data = run_inference(interpreter, preprocessed_image)\n",
    "\n",
    "print(output_data)  # Process the output data as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec8bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141f1823",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:92\u001b[39m, in \u001b[36mNewCheckpointReader\u001b[39m\u001b[34m(filepattern)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for variables/variables",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:1042\u001b[39m, in \u001b[36mload_partial\u001b[39m\u001b[34m(export_dir, filters, tags, options)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m   loader = \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.NotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:226\u001b[39m, in \u001b[36mLoader.__init__\u001b[39m\u001b[34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_options.experimental_skip_checkpoint:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_restore_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:561\u001b[39m, in \u001b[36mLoader._restore_checkpoint\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m   load_status = \u001b[43msaver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkpoint_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m   load_status.assert_existing_objects_matched()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:1456\u001b[39m, in \u001b[36mTrackableSaver.restore\u001b[39m\u001b[34m(self, save_path, options)\u001b[39m\n\u001b[32m   1455\u001b[39m   _ASYNC_CHECKPOINT_THREAD.join()\n\u001b[32m-> \u001b[39m\u001b[32m1456\u001b[39m reader = \u001b[43mpy_checkpoint_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNewCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1457\u001b[39m graph_building = \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:96\u001b[39m, in \u001b[36mNewCheckpointReader\u001b[39m\u001b[34m(filepattern)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[39m, in \u001b[36merror_translator\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mnot found in checkpoint\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFailed to find any \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmatching files for\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl.NotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mSliced checkpoints are not supported\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mData type \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnot \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msupported\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n",
      "\u001b[31mNotFoundError\u001b[39m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for variables/variables",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m tflite_model_path = \u001b[33m\"\u001b[39m\u001b[33myolov9.tflite\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Convert the SavedModel to TFLite\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m converter = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFLiteConverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Optimization settings (optional, but recommended)\u001b[39;00m\n\u001b[32m     12\u001b[39m converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:2262\u001b[39m, in \u001b[36mTFLiteConverterV2.from_saved_model\u001b[39m\u001b[34m(cls, saved_model_dir, signature_keys, tags)\u001b[39m\n\u001b[32m   2259\u001b[39m   tags = \u001b[38;5;28mset\u001b[39m([_tag_constants.SERVING])\n\u001b[32m   2261\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context.eager_mode():\n\u001b[32m-> \u001b[39m\u001b[32m2262\u001b[39m   saved_model = \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signature_keys:\n\u001b[32m   2264\u001b[39m   signature_keys = \u001b[38;5;28mlist\u001b[39m(saved_model.signatures.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:912\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(export_dir, tags, options)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os.PathLike):\n\u001b[32m    911\u001b[39m   export_dir = os.fspath(export_dir)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m result = \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mroot\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IoT/Code/myenvIot/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:1045\u001b[39m, in \u001b[36mload_partial\u001b[39m\u001b[34m(export_dir, filters, tags, options)\u001b[39m\n\u001b[32m   1042\u001b[39m   loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[32m   1043\u001b[39m                   ckpt_options, options, filters)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.NotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m1045\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m   1046\u001b[39m       \u001b[38;5;28mstr\u001b[39m(err) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m You may be trying to load on a different device \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1047\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mfrom the computational device. Consider setting the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1048\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1049\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mto the io_device such as \u001b[39m\u001b[33m'\u001b[39m\u001b[33m/job:localhost\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1050\u001b[39m root = loader.get(\u001b[32m0\u001b[39m)\n\u001b[32m   1051\u001b[39m root.graph_debug_info = loader.adjust_debug_info_func_names(debug_info)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Path to the SavedModel directory\n",
    "saved_model_dir = \"\"  # Replace with your actual path\n",
    "# Path where the TFLite model will be saved\n",
    "tflite_model_path = \"yolov9.tflite\"\n",
    "\n",
    "# Convert the SavedModel to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# Optimization settings (optional, but recommended)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16] # if you want to use float16 quantization\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to {tflite_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvIot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
